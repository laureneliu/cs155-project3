{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Shakespeare.txt\n",
    "# LSTM is character-based, so we want each sonnet as a single all-lowercase string\n",
    "# Punctuation included, leading spaces removed (couplet not formatted)\n",
    "\n",
    "# This was originally written on Google Colab\n",
    "# Change this section as needed to load file\n",
    "downloaded = drive.CreateFile({'id':'1cwaY0yRvUNgggFytJpca_1Mao85bawQN'})\n",
    "downloaded.GetContentFile('filename.txt')\n",
    "f = open('filename.txt')\n",
    "\n",
    "data = []\n",
    "accum = ''\n",
    "\n",
    "for line in f:\n",
    "  # Case: just a newline\n",
    "  if len(line) == 1: \n",
    "    continue\n",
    "  # Case: line contains only a number--beginning of new sonnet\n",
    "  elif line.strip(' ').strip('\\n').isnumeric():\n",
    "    if len(accum) != 0:\n",
    "      accum += END_OF_SONNET\n",
    "      data.append(accum)\n",
    "      accum = ''\n",
    "  # Case: line of sonnet\n",
    "  else:\n",
    "    accum += line.strip(' ').lower()\n",
    "\n",
    "data = np.array(data)\n",
    "print(f'data.shape: {data.shape}')\n",
    "print('')\n",
    "print(f'data[0]: {data[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset of 40-character strings\n",
    "# To speed up training, we use semi-redundant sequences, picking 40-character sequences starting every n characters\n",
    "# X1 is array of 40-character strings\n",
    "# Y1 is array containing the next character\n",
    "\n",
    "window = 40\n",
    "n = 5\n",
    "\n",
    "X1 = []\n",
    "Y1 = []\n",
    "for sonnet in data:\n",
    "  for i in range(0, len(sonnet)-window-1, n):\n",
    "    X1.append(sonnet[i:i+window])\n",
    "    Y1.append(sonnet[i+window])\n",
    "\n",
    "print(f'len(X1): {len(X1)}\\t len(Y1): {len(Y1)}')\n",
    "print('')\n",
    "print(f'X1[0]: {X1[0]}')\n",
    "print(f'Y1[0]: {Y1[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN expects each character as a boolean array\n",
    "\n",
    "# rev_mapping: int -> char\n",
    "rev_mapping = set()\n",
    "rev_mapping.update(''.join(data))\n",
    "rev_mapping = np.array(list(rev_mapping))\n",
    "\n",
    "# mapping: character --> boolean array\n",
    "I = np.identity(len(s))\n",
    "mapping = {k:I[v] for v,k in enumerate(rev_mapping)}\n",
    "\n",
    "X = np.array([[mapping[k] for k in seq] for seq in X1])\n",
    "Y = np.array([mapping[k] for k in Y1])\n",
    "\n",
    "print(f'X.shape: {X.shape}\\t Y.shape): {Y.shape}')\n",
    "print('')\n",
    "print(f'X[0]: {X[0]}')\n",
    "print('')\n",
    "print(f'Y[0]: {Y[0]}')\n",
    "print('')\n",
    "print(f'rev_mapping: {rev_mapping}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = Sequential([\n",
    "                    LSTM(200, input_shape=(window,len(mapping))),\n",
    "                    Dense(len(mapping), activation='softmax')\n",
    "])\n",
    "rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "rnn.fit(X, Y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Um, these are still a bit nonsense. Did I do something else wrong?\n",
    "def generate(seed, temperature=1):\n",
    "  x = seed.lower()\n",
    "  x = np.array([mapping[k] for k in x]).reshape((1,len(seed),len(s)))\n",
    "  z = np.log(rnn.predict(x).flatten())\n",
    "  q = np.exp(z / temperature)\n",
    "  q /= np.sum(q)\n",
    "  return np.random.choice(rev_mapping, p=q)\n",
    "\n",
    "def generate_sequence(seq, temperature=1, max_len=4000):\n",
    "  while seq[-1] != END_OF_SONNET and len(seq) < max_len:\n",
    "    seq += generate(seq[len(seq)-40:])\n",
    "  return seq\n",
    "\n",
    "for temp in [1.5, 0.75, 0.25, 0.01]:\n",
    "  seq = generate_sequence('shall i compare thee to a summer\\'s day?\\n',\n",
    "                          temperature=temp)\n",
    "  print(f'{temp}: {seq}\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
